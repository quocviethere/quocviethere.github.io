[
  {
    "objectID": "notes/gaussian-distribution/sm/sm.html#sliced-score-matching",
    "href": "notes/gaussian-distribution/sm/sm.html#sliced-score-matching",
    "title": "Score Matching",
    "section": "",
    "text": "The main intuition behind Sliced score matching (Song et al. 2019) is that working with low-dimensional data is easier than high-dimensional data. Therefore we can project the high-dimensional data into a lower dimension space according to some random direction \\(\\mathbf{v}\\).\nProjecting \\(s_d(\\mathbf{x})\\) and \\(s_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\) onto some random direction \\(\\mathbf{v}\\) and propose to compare their average difference along that random direction. Consider the following objective as an alternative to the Fisher Divergence: \\[\nL(\\boldsymbol{\\theta};p_{\\mathbf{v}}) := \\dfrac{1}{2} \\mathbb{E}_{p_{\\mathbf{v}}} \\mathbb{E}_{p_{\\mathbf{d}}} [(\\mathbf{v}^{T}s_{m}(\\mathbf{x};\\boldsymbol{\\theta}) -\\mathbf{v}^{T}s_{d}(\\mathbf{x}))^{2}]  \n\\] where \\(\\mathbf{v} \\sim p_\\mathbf{v}\\) and \\(\\mathbf{x} \\sim p_{d}\\) are independent, and we require\nFor instance \\(p_\\mathbf{v}\\) can be a multivariate standard normal \\(\\mathcal{N}(0,I_{D})\\), a multivariate Rademacher distribution (the uniform distribution over \\(\\{+1\\}^{D}\\)), or a uniform distribution over a hypersphere \\(\\mathbb{S}^{D-1}\\). \\[J(\\boldsymbol{\\theta};p_{\\mathbf{v}}):=\\mathbb{E}_{{p_{\\mathbf{v}}}}\\mathbb{E}_{{p_{d}}}{\\left[\\mathbf{v}^{\\mathsf{T}}\\nabla_{\\mathbf{x}}\\boldsymbol{s}_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\mathbf{v}+\\frac{1}{2}\\left(\\mathbf{v}^{\\mathsf{T}}\\boldsymbol{s}_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\right)^{2}\\right]}\\]"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Notes",
    "section": "",
    "text": "Welcome! On this page you can find a collection of my scribe notes for self-reference and learning purposes. Sometimes the notes can be woefully incomplete and so please don’t judge. There certainly are typos and other technical errors. I would really appreciate it if you could contact me via my email for further feedback and discussion.\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\nThe Exponential Family\n\n\n\n\n\n\nstats\n\n\n\n\n\n\nJul 4, 2024\n\n\n\n\n\n\n\nGaussian Distribution\n\n\n\n\n\n\nstats\n\n\n\n\n\n\nJul 3, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Viet Nguyen",
    "section": "",
    "text": "About me\nHi, I am currently a junior student majoring in Data Science at University of Economics Ho Chi Minh City (UEH). My research lies in multimodal models  and generative models. I am also keen to work on models’ interpretability.\n\n\nNews\n\nJuly 2024: I will join VIASM’s Summer School Series on Mathematical Statistics and Machine Learning\nApr 2024: I received the UEH Young Researcher 2024 Award.\nFeb 2024: Our paper has been accepted at Journal of Uncertain Systems.\nMar 2023: Our paper has been accepted at ICICCT2023.\nFeb 2023: I received the UEH Young Researcher 2023 Award.\nAug 2021: I was awarded the UEH Admission Scholarship.\n\n\n\nMedia Coverage\n\nUEH Data Science student published 3 Scopus-indexed papers (in Vietnamese)\n\n\n\nContact\nEmail: quocviethere [at] gmail.com"
  },
  {
    "objectID": "pubs.html",
    "href": "pubs.html",
    "title": "Publications",
    "section": "",
    "text": "Performance Insights of Attention-free Language Models in Sentiment Analysis: A Case Study for E-commerce Platforms in Vietnam Nguyen Q. Viet, Nguyen N. Quang, Nguyen King, Dang N.H. Thanh. 8th International Conference on Inventive Communication and Computational Technologies (ICICCT2024)\nAn Exploratory Comparison of LSTM and BiLSTM in Stock Prediction Nguyen Q. Viet, Nguyen N. Quang, Nguyen King, Dinh T. Huu, Nguyen D. Toan, Dang N.H. Thanh. 7th International Conference on Inventive Communication and Computational Technologies (ICICCT2023)"
  },
  {
    "objectID": "pubs.html#conferences",
    "href": "pubs.html#conferences",
    "title": "Publications",
    "section": "",
    "text": "Performance Insights of Attention-free Language Models in Sentiment Analysis: A Case Study for E-commerce Platforms in Vietnam Nguyen Q. Viet, Nguyen N. Quang, Nguyen King, Dang N.H. Thanh. 8th International Conference on Inventive Communication and Computational Technologies (ICICCT2024)\nAn Exploratory Comparison of LSTM and BiLSTM in Stock Prediction Nguyen Q. Viet, Nguyen N. Quang, Nguyen King, Dinh T. Huu, Nguyen D. Toan, Dang N.H. Thanh. 7th International Conference on Inventive Communication and Computational Technologies (ICICCT2023)"
  },
  {
    "objectID": "pubs.html#journals",
    "href": "pubs.html#journals",
    "title": "Publications",
    "section": "Journals",
    "text": "Journals\nCustomer Intent Mining from Service Inquiries with Improved Deep Embedded Clustering Nguyen Q.K. Ha, Nguyen T.T. Huyen, Mai T.M. Uyen, Nguyen Q. Viet, Nguyen N. Quang, Dang N.H. Thanh. Journal of Uncertain Systems"
  },
  {
    "objectID": "notes/gaussian-distribution/sm/sm.html#denoising-score-matching",
    "href": "notes/gaussian-distribution/sm/sm.html#denoising-score-matching",
    "title": "Score Matching",
    "section": "",
    "text": "Denoising Score Matching (DSM) is a variant of score matching that does not require the Hessian computation. Consider a noise distribution \\(q_{\\sigma}(\\mathbf{\\tilde{x}} \\vert \\mathbf{x})\\), and let \\(q_{\\sigma}(\\mathbf{x}) = \\int q_{\\sigma}(\\mathbf{\\tilde{x}} \\vert \\mathbf{x}) p_{d}(\\mathbf{x})d\\mathbf{x}\\). DSM applies the original score matching to the noise-corrupted data distribution \\(q_{\\sigma}(\\tilde{\\mathbf{x}})\\) and the objective can be proven to be equivalent up to a constant.\nWhile DSM is much faster than score matching, it does have several drawbacks, including (1) it can only recover the noise corrupted data distribution; (2) it is hard to choose the parameters of the noise distribution"
  },
  {
    "objectID": "notes/gaussian-distribution/sm/sm.html",
    "href": "notes/gaussian-distribution/sm/sm.html",
    "title": "Score Matching",
    "section": "",
    "text": "Denoising Score Matching (DSM) is a variant of score matching that does not require the Hessian computation. Consider a noise distribution \\(q_{\\sigma}(\\mathbf{\\tilde{x}} \\vert \\mathbf{x})\\), and let \\(q_{\\sigma}(\\mathbf{x}) = \\int q_{\\sigma}(\\mathbf{\\tilde{x}} \\vert \\mathbf{x}) p_{d}(\\mathbf{x})d\\mathbf{x}\\). DSM applies the original score matching to the noise-corrupted data distribution \\(q_{\\sigma}(\\tilde{\\mathbf{x}})\\) and the objective can be proven to be equivalent up to a constant.\nWhile DSM is much faster than score matching, it does have several drawbacks, including (1) it can only recover the noise corrupted data distribution; (2) it is hard to choose the parameters of the noise distribution\n\n\n\nThe main intuition behind Sliced score matching (Song et al. 2019) is that working with low-dimensional data is easier than high-dimensional data. Therefore we can project the high-dimensional data into a lower dimension space according to some random direction \\(\\mathbf{v}\\).\nProjecting \\(s_d(\\mathbf{x})\\) and \\(s_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\) onto some random direction \\(\\mathbf{v}\\) and propose to compare their average difference along that random direction. Consider the following objective as an alternative to the Fisher Divergence: \\[\nL(\\boldsymbol{\\theta};p_{\\mathbf{v}}) := \\dfrac{1}{2} \\mathbb{E}_{p_{\\mathbf{v}}} \\mathbb{E}_{p_{\\mathbf{d}}} [(\\mathbf{v}^{T}s_{m}(\\mathbf{x};\\boldsymbol{\\theta}) -\\mathbf{v}^{T}s_{d}(\\mathbf{x}))^{2}]  \n\\] where \\(\\mathbf{v} \\sim p_\\mathbf{v}\\) and \\(\\mathbf{x} \\sim p_{d}\\) are independent, and we require\nFor instance \\(p_\\mathbf{v}\\) can be a multivariate standard normal \\(\\mathcal{N}(0,I_{D})\\), a multivariate Rademacher distribution (the uniform distribution over \\(\\{+1\\}^{D}\\)), or a uniform distribution over a hypersphere \\(\\mathbb{S}^{D-1}\\). \\[J(\\boldsymbol{\\theta};p_{\\mathbf{v}}):=\\mathbb{E}_{{p_{\\mathbf{v}}}}\\mathbb{E}_{{p_{d}}}{\\left[\\mathbf{v}^{\\mathsf{T}}\\nabla_{\\mathbf{x}}\\boldsymbol{s}_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\mathbf{v}+\\frac{1}{2}\\left(\\mathbf{v}^{\\mathsf{T}}\\boldsymbol{s}_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\right)^{2}\\right]}\\]"
  },
  {
    "objectID": "notes/gaussian-distribution/expfam/expfam.html",
    "href": "notes/gaussian-distribution/expfam/expfam.html",
    "title": "Motivation",
    "section": "",
    "text": "The classical motivation for exponential family comes from the principle of maximum entropy. Suppose we are given a random sample \\(\\{X_{1}, X_{2}, \\cdots, X_{n}\\}\\) from some distribution, and we compute the empirical expectations of certain functions that we choose: \\[\\hat{\\mu}_{i}=\\dfrac{1}{n}\\sum\\limits_{j=1}^{n}T_{i}(X_{j}) \\quad \\text{for } i \\in \\{1, \\cdots, s\\}\\] Based on these empirical expectations we want to infer a full probability distribution on the samples. A distribution \\(p\\) is said to be consistent 1 with the data we observe if: \\[\n\\hat{\\mu}_{i} = \\mathbb{E}_{p}[T_{i}(X_{i})] \\quad \\text{for } i \\in \\{1, \\cdots, s\\}.\n\\] We want to pick a consistent distribution but there are infinitely many distributions to choose from. The principle of maximum entropy suggests to pick the distribution with the largest entropy 2, which is defined as: \\[\nH(p) = - \\int p(x) \\log p(x) dx\n\\] Formally, we could pose our problem as finding a distribution \\(p^{*}\\) such that: \\[\np^{*} = \\underset{p}{\\text{argmax}} H(p)\n\\] Solving this problem, we get an answer that is of the form 3: \\[\np^{*} = \\exp \\left[\\sum\\limits_{i=1}^{s}\\theta_{i}T_{i}(x) - A(\\theta)\\right]h(x)\n\\] This form motivates the exponential families. # The Exponential Family\n\n\nThe exponential family of probability distributions is defined as a set of distributions whose density can be written in the following form: \\[\np(x \\vert \\eta) = h(x)\\exp\\{\\eta^{T}\\mathcal{T}(x) - \\mathcal{A}(\\eta)\\},\n\\] where: - \\(\\eta\\) is often referred to as natural or canonical parameters - \\(\\mathcal{T}(x)\\) is the sufficient statistic, because the likelihood for \\(x\\) only depends on \\(\\eta\\) and \\(\\mathcal{T}(x)\\) transforms \\(x\\) into sufficient statistic, which is something that summarizes the data well. - \\(\\mathcal{A}(\\eta)\\) is known as the cumulant function, or log-partition function and can be viewed as the logarithm of the normalization factor, i.e.: \\(\\mathcal{A}(\\eta) = \\log \\int h(x) \\exp \\{\\eta^{T}\\mathcal{T}(x)\\}dx\\)\nSometimes, the exponential family can also be represented as: \\[\np(x \\vert \\eta) = h(x) g(\\eta) \\exp \\{\\eta^{T}\\mathcal{T}(x)\\}\n\\] where the \\(g(\\eta)\\) can be interpreted as the coefficient that ensures the distribution is normalized, i.e.: \\[\ng(\\eta) = \\int h(x) \\exp\\{\\eta^{T}\\mathcal{T}(x)\\}\n\\] ## Examples\nThe simplest possible distribution that belongs to the exponential family is the Bernoulli distribution. Recall that we can write the Bernoulli distribution as: \\[\np(x \\vert \\mu) = \\text{Bern}(x \\vert \\mu) = \\mu^{x}(1-\\mu)^{1-x}\n\\] which we can rewrite as: \\[\np(x \\vert \\mu) = \\exp\\{x \\ln \\mu + (1-x)\\ln (1-\\mu)\\} = (1-\\mu) \\exp \\left\\{x\\ln \\left(\\dfrac{\\mu}{1-\\mu}\\right) + \\ln (1-\\mu)\\right\\}  \n\\] We can therefore see that the Bernoulli distribution is in the exponential family distribution where \\(\\mathcal{T}(x) = x; \\eta = \\ln \\left(\\dfrac{\\mu}{1-\\mu}\\right)\\). One interesting fact is that when we solve for \\(\\mu\\), we obtain the well-known logistic function. The derivation is as follows: \\[\n\\begin{aligned}\n\\eta &= \\ln \\left(\\dfrac{\\mu}{1-\\mu}\\right) && (\\text{derived from rewriting Bernoulli distribution})\\\\\n& \\rightarrow \\exp(\\eta) = \\dfrac{\\mu}{1-\\mu} && \\text{(taking exp on both sides)}\\\\\n& \\rightarrow \\mu = \\dfrac{\\exp(\\eta)}{1+\\exp(\\eta)} && \\text{(by basic algebra)}\\\\\n& \\rightarrow \\mu = \\dfrac{1}{1+\\exp(-\\eta)} && \\text{(multiplying by $\\exp(-\\mu)$)}\n\\end{aligned}\n\\] There are many common probability distribution that is in the exponential family. The table below listed some of them.\n\n\n\n\n\n\n\n\nDistribution\nProbability Density / Mass Function\n(\\(x\\)) Values\n\n\n\n\nGaussian\n\\[ p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} \\]\n\\[ x \\in \\mathbb{R} \\]\n\n\nBernoulli\n\\[ p(x) = \\alpha^x (1 - \\alpha)^{1 - x} \\]\n\\[ x \\in \\{0, 1\\} \\]\n\n\nBinomial\n\\[ p(x) = \\binom{n}{x} \\alpha^x (1 - \\alpha)^{n - x} \\]\n\\[ x \\in \\{0, 1, 2, \\ldots, n\\} \\]\n\n\nMultinomial\n\\[ p(x) = \\frac{n!}{x_1! x_2! \\ldots x_n!} \\prod_{i=1}^{n} \\alpha_i^{x_i} \\]\n\\[ x_i \\in \\{0, 1, 2, \\ldots, n\\}, \\sum x_i = n \\]\n\n\nExponential\n\\[ p(x) = \\lambda e^{-\\lambda x} \\]\n\\[ x \\in \\mathbb{R}^+ \\]\n\n\nPoisson\n\\[ p(x) = \\frac{e^{-\\lambda} \\lambda^x}{x!} \\]\n\\[ x \\in \\{0, 1, 2, \\ldots \\} \\]\n\n\nDirichlet\n\\[ p(x) = \\frac{\\Gamma \\left( \\sum_i \\alpha_i \\right)}{\\prod_i \\Gamma(\\alpha_i)} \\prod_i x_i^{\\alpha_i - 1} \\]\n\\[ x_i \\in [0, 1], \\sum x_i = 1 \\]"
  },
  {
    "objectID": "notes/gaussian-distribution/expfam/expfam.html#definition",
    "href": "notes/gaussian-distribution/expfam/expfam.html#definition",
    "title": "Motivation",
    "section": "",
    "text": "The exponential family of probability distributions is defined as a set of distributions whose density can be written in the following form: \\[\np(x \\vert \\eta) = h(x)\\exp\\{\\eta^{T}\\mathcal{T}(x) - \\mathcal{A}(\\eta)\\},\n\\] where: - \\(\\eta\\) is often referred to as natural or canonical parameters - \\(\\mathcal{T}(x)\\) is the sufficient statistic, because the likelihood for \\(x\\) only depends on \\(\\eta\\) and \\(\\mathcal{T}(x)\\) transforms \\(x\\) into sufficient statistic, which is something that summarizes the data well. - \\(\\mathcal{A}(\\eta)\\) is known as the cumulant function, or log-partition function and can be viewed as the logarithm of the normalization factor, i.e.: \\(\\mathcal{A}(\\eta) = \\log \\int h(x) \\exp \\{\\eta^{T}\\mathcal{T}(x)\\}dx\\)\nSometimes, the exponential family can also be represented as: \\[\np(x \\vert \\eta) = h(x) g(\\eta) \\exp \\{\\eta^{T}\\mathcal{T}(x)\\}\n\\] where the \\(g(\\eta)\\) can be interpreted as the coefficient that ensures the distribution is normalized, i.e.: \\[\ng(\\eta) = \\int h(x) \\exp\\{\\eta^{T}\\mathcal{T}(x)\\}\n\\] ## Examples\nThe simplest possible distribution that belongs to the exponential family is the Bernoulli distribution. Recall that we can write the Bernoulli distribution as: \\[\np(x \\vert \\mu) = \\text{Bern}(x \\vert \\mu) = \\mu^{x}(1-\\mu)^{1-x}\n\\] which we can rewrite as: \\[\np(x \\vert \\mu) = \\exp\\{x \\ln \\mu + (1-x)\\ln (1-\\mu)\\} = (1-\\mu) \\exp \\left\\{x\\ln \\left(\\dfrac{\\mu}{1-\\mu}\\right) + \\ln (1-\\mu)\\right\\}  \n\\] We can therefore see that the Bernoulli distribution is in the exponential family distribution where \\(\\mathcal{T}(x) = x; \\eta = \\ln \\left(\\dfrac{\\mu}{1-\\mu}\\right)\\). One interesting fact is that when we solve for \\(\\mu\\), we obtain the well-known logistic function. The derivation is as follows: \\[\n\\begin{aligned}\n\\eta &= \\ln \\left(\\dfrac{\\mu}{1-\\mu}\\right) && (\\text{derived from rewriting Bernoulli distribution})\\\\\n& \\rightarrow \\exp(\\eta) = \\dfrac{\\mu}{1-\\mu} && \\text{(taking exp on both sides)}\\\\\n& \\rightarrow \\mu = \\dfrac{\\exp(\\eta)}{1+\\exp(\\eta)} && \\text{(by basic algebra)}\\\\\n& \\rightarrow \\mu = \\dfrac{1}{1+\\exp(-\\eta)} && \\text{(multiplying by $\\exp(-\\mu)$)}\n\\end{aligned}\n\\] There are many common probability distribution that is in the exponential family. The table below listed some of them.\n\n\n\n\n\n\n\n\nDistribution\nProbability Density / Mass Function\n(\\(x\\)) Values\n\n\n\n\nGaussian\n\\[ p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} \\]\n\\[ x \\in \\mathbb{R} \\]\n\n\nBernoulli\n\\[ p(x) = \\alpha^x (1 - \\alpha)^{1 - x} \\]\n\\[ x \\in \\{0, 1\\} \\]\n\n\nBinomial\n\\[ p(x) = \\binom{n}{x} \\alpha^x (1 - \\alpha)^{n - x} \\]\n\\[ x \\in \\{0, 1, 2, \\ldots, n\\} \\]\n\n\nMultinomial\n\\[ p(x) = \\frac{n!}{x_1! x_2! \\ldots x_n!} \\prod_{i=1}^{n} \\alpha_i^{x_i} \\]\n\\[ x_i \\in \\{0, 1, 2, \\ldots, n\\}, \\sum x_i = n \\]\n\n\nExponential\n\\[ p(x) = \\lambda e^{-\\lambda x} \\]\n\\[ x \\in \\mathbb{R}^+ \\]\n\n\nPoisson\n\\[ p(x) = \\frac{e^{-\\lambda} \\lambda^x}{x!} \\]\n\\[ x \\in \\{0, 1, 2, \\ldots \\} \\]\n\n\nDirichlet\n\\[ p(x) = \\frac{\\Gamma \\left( \\sum_i \\alpha_i \\right)}{\\prod_i \\Gamma(\\alpha_i)} \\prod_i x_i^{\\alpha_i - 1} \\]\n\\[ x_i \\in [0, 1], \\sum x_i = 1 \\]"
  },
  {
    "objectID": "notes/gaussian-distribution/expfam/expfam.html#random-sampling",
    "href": "notes/gaussian-distribution/expfam/expfam.html#random-sampling",
    "title": "Motivation",
    "section": "Random sampling",
    "text": "Random sampling\nThe exponential family structure is preserved for an i.i.d. sample. If \\(\\{X_{1}, \\cdots, X_{n}\\}\\) are i.i.d. from some distribution in the exponential family \\(p(x; \\theta)\\), then the joint distribution: \\[\np(x_{1}, \\cdots, x_{n};\\theta) = \\prod_{i=1}^{n}h(x_{i})\\exp \\left[\\sum\\limits_{i=1}^{s}\\theta_{i}\\sum\\limits_{j=1}^{n}\\mathcal{T}_{i}(x_{j}) - \\eta\\mathcal{A}(\\theta)\\right]\n\\] is an exponential family with the same natural parameters but with sufficient statistics: \\[\n\\mathcal{T}_{i}(x_{1}, \\cdots, x_{n)}= \\sum\\limits_{j=1}^{n}T_i(x_{j})\n\\] d ## Log-partition generates moments\nTaking the derivative of \\(\\mathcal{A}\\) w.r.t. \\(\\theta\\), we obtain that:\\[\n\\begin{aligned}\n\\dfrac{d\\mathcal{A}}{d\\eta}\n&= \\dfrac{d}{d\\eta} \\log \\int \\exp(\\eta^{T} \\mathcal{T}(x))h(x) dx \\\\\n&= \\dfrac{\\dfrac{d}{d\\eta} \\int \\exp(\\eta^{T} \\mathcal{T}(x)h(x)dx}{\\int \\exp(\\eta^{T} \\mathcal{T}(x)h(x)dx} \\\\\n&= \\dfrac{\\int \\mathcal{T}(x) \\exp(\\eta^{T} \\mathcal{T}(x)h(x)dx}{\\exp(\\mathcal{A}(\\eta))} \\\\\n&= \\int \\mathcal{T}(x) \\exp(\\eta \\mathcal{T}(x) - \\mathcal{A}(\\eta))h(x)dx \\\\\n&= \\int \\mathcal{T}(x) p(x)dx = \\mathbb{E}[\\mathcal{T}(x)]\n\\end{aligned}\n\\]a concrete example, recall that for Bernoulli distribution, we have \\(\\mathcal{A}(\\eta) = \\log (1+e^{\\eta})\\), we can take the first-order derivative of the log-partition function and obtain the mean for Bernoulli random variables: \\[\n\\dfrac{d\\mathcal{A}}{d\\eta} = \\dfrac{d}{d\\eta} \\log (1+e^{\\eta}) = \\dfrac{e^{\\eta}}{1+e^{\\eta}} = \\dfrac{1}{1+e^{-\\eta}} = \\sigma(\\eta) = \\mu\n\\] Similarly, we can verify that higher derivatives lead to functions of higher moments as follows: \\[\n\\begin{aligned}\n\\dfrac{d^{2}\\mathcal{A}}{d\\eta} &= \\dfrac{d\\mathcal{A}}{d\\eta} \\int \\mathcal{T}(x)\\exp (\\eta^{T}\\mathcal{T}(x) - \\mathcal{A}(\\eta))h(x)dx \\\\\n&= \\int \\mathcal{T}(x) \\exp (\\eta^{T}\\mathcal{T}(x) - \\mathcal{A}(\\eta))h(x)(\\mathcal{T}(x) - \\mathcal{A}'(\\eta))dx \\\\\n&= \\int \\mathcal{T}(x)p(x)(\\mathcal{T}(x) - \\mathcal{A}'(x))dx \\\\\n&= \\int \\mathcal{T}^{2}(x)p(x)dx - \\mathcal{A}'(x)\\int \\mathcal{T}(x)p(x)dx \\\\\n&= \\mathbb{E}[\\mathcal{T}^{2}(x)] - \\mathbb{E}[\\mathcal{T}(x)]^{2} = \\text{Var}[\\mathcal{T}(x)]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "notes/gaussian-distribution/expfam/expfam.html#footnotes",
    "href": "notes/gaussian-distribution/expfam/expfam.html#footnotes",
    "title": "Motivation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhen a distribution is consistent, it means that the values are spread out in a way that shows a clear and predictable pattern. In other words, if you take multiple samples from the distribution, they should all look similar to each other and follow the same pattern or trend. This consistency makes it easier to understand and predict the behavior of the data.↩︎\nEntropy is a measure of this unpredictability or randomness. In statistics, it tells us how mixed up or uncertain the data is. High entropy means the data is very mixed and unpredictable. Low entropy means the data is more uniform and predictable.↩︎\nWe will show later that we can actually derive the probability distributions that belong to the exponential family by solving this problem but with different constraints.↩︎"
  },
  {
    "objectID": "notes/gaussian-distribution/expfam/expfam.html#convexity",
    "href": "notes/gaussian-distribution/expfam/expfam.html#convexity",
    "title": "Motivation",
    "section": "Convexity",
    "text": "Convexity\nUsing Hölder inequality together with this results, we can show that \\(\\mathcal{A}\\) is a convex function of \\(\\theta\\). In the case of the exponential family, this means that the covariance matrix (equivalent to the Hessian matrix) of the sufficient statistic \\(\\mathcal{T}_{i}\\) is positive semidefinite. Formally, we have the following theorem:\n\nThe natural parameter space \\(\\mathcal{N}\\) is a convex set and the cumulant function \\(\\mathcal{A}(\\eta)\\) is a convex function. If the family is minimal then \\(\\mathcal{A}(\\eta)\\) is strictly convex.\n\nHere, we say that an exponential family is minimal if the sufficient statistic are not redundant, i.e. there is no set of coefficients \\(\\alpha \\in \\mathbb{R}^s\\), \\(\\alpha \\# 0\\) such that: \\[\n\\sum\\limits_{i=1}^{s}\\alpha_{i}\\mathcal{T}_{i}(x) = \\text{const} \\qquad \\forall x\\in \\mathbb{R}\n\\] # Connection with Fisher information matrix\nUnder some regularity condition, the [[Fisher Information matrix]] is given by: \\[\n\\mathbf{F}(\\eta) \\triangleq \\mathbb{E}_{p(x\\vert \\eta)} [\\nabla \\log p(x \\vert \\eta) \\nabla \\log p(x \\vert \\eta)^{T}] = -\\mathbb{E}_{p(x \\vert \\eta)} [\\nabla^{2}\\log p(x\\vert \\eta)]\n\\] Recall that in the context of the exponential family, we have\nFrom the definition of the Fisher Information matrix, we can derive the following: \\[\n\\begin{aligned}\n\\mathbf{F}(\\eta) &= -\\mathbb{E}_{p(x\\vert \\eta)}[\\nabla^{2}\\log p(x\\vert \\eta)] && \\text{(by definition)}\\\\\n&= -\\mathbb{E}_{p(x \\vert \\eta)}[\\nabla^{2}_{\\eta}(\\eta^{T} \\mathcal{T}(x) - \\mathcal{A(\\eta)})] && \\text{(plug in $p(x \\vert \\eta)$)} \\\\\n&= \\nabla^{2}_{\\eta}\\mathcal{A} (\\eta) = \\text{Cov}[\\mathcal{T}(x)]\n\\end{aligned}\n\\] Intuitively, this is telling us that the Hessian of the log-partition function is the same as the Fisher Information matrix, which is the same as the covariance of the sufficient statistic."
  },
  {
    "objectID": "notes/sm/sm.html",
    "href": "notes/sm/sm.html",
    "title": "Generative Score Models",
    "section": "",
    "text": "Denoising Score Matching (DSM) is a variant of score matching that does not require the Hessian computation. Consider a noise distribution \\(q_{\\sigma}(\\mathbf{\\tilde{x}} \\vert \\mathbf{x})\\), and let \\(q_{\\sigma}(\\mathbf{x}) = \\int q_{\\sigma}(\\mathbf{\\tilde{x}} \\vert \\mathbf{x}) p_{d}(\\mathbf{x})d\\mathbf{x}\\). DSM applies the original score matching to the noise-corrupted data distribution \\(q_{\\sigma}(\\tilde{\\mathbf{x}})\\) and the objective can be proven to be equivalent up to a constant.\nWhile DSM is much faster than score matching, it does have several drawbacks, including (1) it can only recover the noise corrupted data distribution; (2) it is hard to choose the parameters of the noise distribution\n\n\n\nThe main intuition behind Sliced score matching (Song et al. 2019) is that working with low-dimensional data is easier than high-dimensional data. Therefore we can project the high-dimensional data into a lower dimension space according to some random direction \\(\\mathbf{v}\\).\nProjecting \\(s_d(\\mathbf{x})\\) and \\(s_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\) onto some random direction \\(\\mathbf{v}\\) and propose to compare their average difference along that random direction. Consider the following objective as an alternative to the Fisher Divergence: \\[\nL(\\boldsymbol{\\theta};p_{\\mathbf{v}}) := \\dfrac{1}{2} \\mathbb{E}_{p_{\\mathbf{v}}} \\mathbb{E}_{p_{\\mathbf{d}}} [(\\mathbf{v}^{T}s_{m}(\\mathbf{x};\\boldsymbol{\\theta}) -\\mathbf{v}^{T}s_{d}(\\mathbf{x}))^{2}]  \n\\] where \\(\\mathbf{v} \\sim p_\\mathbf{v}\\) and \\(\\mathbf{x} \\sim p_{d}\\) are independent, and we require\nFor instance \\(p_\\mathbf{v}\\) can be a multivariate standard normal \\(\\mathcal{N}(0,I_{D})\\), a multivariate Rademacher distribution (the uniform distribution over \\(\\{+1\\}^{D}\\)), or a uniform distribution over a hypersphere \\(\\mathbb{S}^{D-1}\\). \\[J(\\boldsymbol{\\theta};p_{\\mathbf{v}}):=\\mathbb{E}_{{p_{\\mathbf{v}}}}\\mathbb{E}_{{p_{d}}}{\\left[\\mathbf{v}^{\\mathsf{T}}\\nabla_{\\mathbf{x}}\\boldsymbol{s}_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\mathbf{v}+\\frac{1}{2}\\left(\\mathbf{v}^{\\mathsf{T}}\\boldsymbol{s}_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\right)^{2}\\right]}\\]"
  },
  {
    "objectID": "notes/sm/sm.html#denoising-score-matching",
    "href": "notes/sm/sm.html#denoising-score-matching",
    "title": "Generative Score Models",
    "section": "",
    "text": "Denoising Score Matching (DSM) is a variant of score matching that does not require the Hessian computation. Consider a noise distribution \\(q_{\\sigma}(\\mathbf{\\tilde{x}} \\vert \\mathbf{x})\\), and let \\(q_{\\sigma}(\\mathbf{x}) = \\int q_{\\sigma}(\\mathbf{\\tilde{x}} \\vert \\mathbf{x}) p_{d}(\\mathbf{x})d\\mathbf{x}\\). DSM applies the original score matching to the noise-corrupted data distribution \\(q_{\\sigma}(\\tilde{\\mathbf{x}})\\) and the objective can be proven to be equivalent up to a constant.\nWhile DSM is much faster than score matching, it does have several drawbacks, including (1) it can only recover the noise corrupted data distribution; (2) it is hard to choose the parameters of the noise distribution"
  },
  {
    "objectID": "notes/sm/sm.html#sliced-score-matching",
    "href": "notes/sm/sm.html#sliced-score-matching",
    "title": "Generative Score Models",
    "section": "",
    "text": "The main intuition behind Sliced score matching (Song et al. 2019) is that working with low-dimensional data is easier than high-dimensional data. Therefore we can project the high-dimensional data into a lower dimension space according to some random direction \\(\\mathbf{v}\\).\nProjecting \\(s_d(\\mathbf{x})\\) and \\(s_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\) onto some random direction \\(\\mathbf{v}\\) and propose to compare their average difference along that random direction. Consider the following objective as an alternative to the Fisher Divergence: \\[\nL(\\boldsymbol{\\theta};p_{\\mathbf{v}}) := \\dfrac{1}{2} \\mathbb{E}_{p_{\\mathbf{v}}} \\mathbb{E}_{p_{\\mathbf{d}}} [(\\mathbf{v}^{T}s_{m}(\\mathbf{x};\\boldsymbol{\\theta}) -\\mathbf{v}^{T}s_{d}(\\mathbf{x}))^{2}]  \n\\] where \\(\\mathbf{v} \\sim p_\\mathbf{v}\\) and \\(\\mathbf{x} \\sim p_{d}\\) are independent, and we require\nFor instance \\(p_\\mathbf{v}\\) can be a multivariate standard normal \\(\\mathcal{N}(0,I_{D})\\), a multivariate Rademacher distribution (the uniform distribution over \\(\\{+1\\}^{D}\\)), or a uniform distribution over a hypersphere \\(\\mathbb{S}^{D-1}\\). \\[J(\\boldsymbol{\\theta};p_{\\mathbf{v}}):=\\mathbb{E}_{{p_{\\mathbf{v}}}}\\mathbb{E}_{{p_{d}}}{\\left[\\mathbf{v}^{\\mathsf{T}}\\nabla_{\\mathbf{x}}\\boldsymbol{s}_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\mathbf{v}+\\frac{1}{2}\\left(\\mathbf{v}^{\\mathsf{T}}\\boldsymbol{s}_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\right)^{2}\\right]}\\]"
  },
  {
    "objectID": "notes/expfam/expfam.html",
    "href": "notes/expfam/expfam.html",
    "title": "The Exponential Family",
    "section": "",
    "text": "The classical motivation for exponential family comes from the principle of maximum entropy. Suppose we are given a random sample \\(\\{X_{1}, X_{2}, \\cdots, X_{n}\\}\\) from some distribution, and we compute the empirical expectations of certain functions that we choose: \\[\\hat{\\mu}_{i}=\\dfrac{1}{n}\\sum\\limits_{j=1}^{n}T_{i}(X_{j}) \\quad \\text{for } i \\in \\{1, \\cdots, s\\}\\] Based on these empirical expectations we want to infer a full probability distribution on the samples. A distribution \\(p\\) is said to be consistent 1 with the data we observe if: \\[\n\\hat{\\mu}_{i} = \\mathbb{E}_{p}[T_{i}(X_{i})] \\quad \\text{for } i \\in \\{1, \\cdots, s\\}.\n\\] We want to pick a consistent distribution but there are infinitely many distributions to choose from. The principle of maximum entropy suggests to pick the distribution with the largest entropy 2, which is defined as: \\[\nH(p) = - \\int p(x) \\log p(x) dx\n\\] Formally, we could pose our problem as finding a distribution \\(p^{*}\\) such that: \\[\np^{*} = \\underset{p}{\\text{argmax}} H(p)\n\\] Solving this problem, we get an answer that is of the form 3: \\[\np^{*} = \\exp \\left[\\sum\\limits_{i=1}^{s}\\theta_{i}T_{i}(x) - A(\\theta)\\right]h(x)\n\\] This form motivates the exponential families. # The Exponential Family\n\n\nThe exponential family of probability distributions is defined as a set of distributions whose density can be written in the following form: \\[\np(x \\vert \\eta) = h(x)\\exp\\{\\eta^{T}\\mathcal{T}(x) - \\mathcal{A}(\\eta)\\},\n\\] where: - \\(\\eta\\) is often referred to as natural or canonical parameters - \\(\\mathcal{T}(x)\\) is the sufficient statistic, because the likelihood for \\(x\\) only depends on \\(\\eta\\) and \\(\\mathcal{T}(x)\\) transforms \\(x\\) into sufficient statistic, which is something that summarizes the data well. - \\(\\mathcal{A}(\\eta)\\) is known as the cumulant function, or log-partition function and can be viewed as the logarithm of the normalization factor, i.e.: \\(\\mathcal{A}(\\eta) = \\log \\int h(x) \\exp \\{\\eta^{T}\\mathcal{T}(x)\\}dx\\)\nSometimes, the exponential family can also be represented as: \\[\np(x \\vert \\eta) = h(x) g(\\eta) \\exp \\{\\eta^{T}\\mathcal{T}(x)\\}\n\\] where the \\(g(\\eta)\\) can be interpreted as the coefficient that ensures the distribution is normalized, i.e.: \\[\ng(\\eta) = \\int h(x) \\exp\\{\\eta^{T}\\mathcal{T}(x)\\}\n\\] ## Examples\nThe simplest possible distribution that belongs to the exponential family is the Bernoulli distribution. Recall that we can write the Bernoulli distribution as: \\[\np(x \\vert \\mu) = \\text{Bern}(x \\vert \\mu) = \\mu^{x}(1-\\mu)^{1-x}\n\\] which we can rewrite as: \\[\np(x \\vert \\mu) = \\exp\\{x \\ln \\mu + (1-x)\\ln (1-\\mu)\\} = (1-\\mu) \\exp \\left\\{x\\ln \\left(\\dfrac{\\mu}{1-\\mu}\\right) + \\ln (1-\\mu)\\right\\}  \n\\] We can therefore see that the Bernoulli distribution is in the exponential family distribution where \\(\\mathcal{T}(x) = x; \\eta = \\ln \\left(\\dfrac{\\mu}{1-\\mu}\\right)\\). One interesting fact is that when we solve for \\(\\mu\\), we obtain the well-known logistic function. The derivation is as follows: \\[\n\\begin{aligned}\n\\eta &= \\ln \\left(\\dfrac{\\mu}{1-\\mu}\\right) && (\\text{derived from rewriting Bernoulli distribution})\\\\\n& \\rightarrow \\exp(\\eta) = \\dfrac{\\mu}{1-\\mu} && \\text{(taking exp on both sides)}\\\\\n& \\rightarrow \\mu = \\dfrac{\\exp(\\eta)}{1+\\exp(\\eta)} && \\text{(by basic algebra)}\\\\\n& \\rightarrow \\mu = \\dfrac{1}{1+\\exp(-\\eta)} && \\text{(multiplying by $\\exp(-\\mu)$)}\n\\end{aligned}\n\\] There are many common probability distribution that is in the exponential family. The table below listed some of them.\n\n\n\n\n\n\n\n\nDistribution\nProbability Density / Mass Function\n(\\(x\\)) Values\n\n\n\n\nGaussian\n\\[ p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} \\]\n\\[ x \\in \\mathbb{R} \\]\n\n\nBernoulli\n\\[ p(x) = \\alpha^x (1 - \\alpha)^{1 - x} \\]\n\\[ x \\in \\{0, 1\\} \\]\n\n\nBinomial\n\\[ p(x) = \\binom{n}{x} \\alpha^x (1 - \\alpha)^{n - x} \\]\n\\[ x \\in \\{0, 1, 2, \\ldots, n\\} \\]\n\n\nMultinomial\n\\[ p(x) = \\frac{n!}{x_1! x_2! \\ldots x_n!} \\prod_{i=1}^{n} \\alpha_i^{x_i} \\]\n\\[ x_i \\in \\{0, 1, 2, \\ldots, n\\}, \\sum x_i = n \\]\n\n\nExponential\n\\[ p(x) = \\lambda e^{-\\lambda x} \\]\n\\[ x \\in \\mathbb{R}^+ \\]\n\n\nPoisson\n\\[ p(x) = \\frac{e^{-\\lambda} \\lambda^x}{x!} \\]\n\\[ x \\in \\{0, 1, 2, \\ldots \\} \\]\n\n\nDirichlet\n\\[ p(x) = \\frac{\\Gamma \\left( \\sum_i \\alpha_i \\right)}{\\prod_i \\Gamma(\\alpha_i)} \\prod_i x_i^{\\alpha_i - 1} \\]\n\\[ x_i \\in [0, 1], \\sum x_i = 1 \\]"
  },
  {
    "objectID": "notes/expfam/expfam.html#definition",
    "href": "notes/expfam/expfam.html#definition",
    "title": "The Exponential Family",
    "section": "",
    "text": "The exponential family of probability distributions is defined as a set of distributions whose density can be written in the following form: \\[\np(x \\vert \\eta) = h(x)\\exp\\{\\eta^{T}\\mathcal{T}(x) - \\mathcal{A}(\\eta)\\},\n\\] where: - \\(\\eta\\) is often referred to as natural or canonical parameters - \\(\\mathcal{T}(x)\\) is the sufficient statistic, because the likelihood for \\(x\\) only depends on \\(\\eta\\) and \\(\\mathcal{T}(x)\\) transforms \\(x\\) into sufficient statistic, which is something that summarizes the data well. - \\(\\mathcal{A}(\\eta)\\) is known as the cumulant function, or log-partition function and can be viewed as the logarithm of the normalization factor, i.e.: \\(\\mathcal{A}(\\eta) = \\log \\int h(x) \\exp \\{\\eta^{T}\\mathcal{T}(x)\\}dx\\)\nSometimes, the exponential family can also be represented as: \\[\np(x \\vert \\eta) = h(x) g(\\eta) \\exp \\{\\eta^{T}\\mathcal{T}(x)\\}\n\\] where the \\(g(\\eta)\\) can be interpreted as the coefficient that ensures the distribution is normalized, i.e.: \\[\ng(\\eta) = \\int h(x) \\exp\\{\\eta^{T}\\mathcal{T}(x)\\}\n\\] ## Examples\nThe simplest possible distribution that belongs to the exponential family is the Bernoulli distribution. Recall that we can write the Bernoulli distribution as: \\[\np(x \\vert \\mu) = \\text{Bern}(x \\vert \\mu) = \\mu^{x}(1-\\mu)^{1-x}\n\\] which we can rewrite as: \\[\np(x \\vert \\mu) = \\exp\\{x \\ln \\mu + (1-x)\\ln (1-\\mu)\\} = (1-\\mu) \\exp \\left\\{x\\ln \\left(\\dfrac{\\mu}{1-\\mu}\\right) + \\ln (1-\\mu)\\right\\}  \n\\] We can therefore see that the Bernoulli distribution is in the exponential family distribution where \\(\\mathcal{T}(x) = x; \\eta = \\ln \\left(\\dfrac{\\mu}{1-\\mu}\\right)\\). One interesting fact is that when we solve for \\(\\mu\\), we obtain the well-known logistic function. The derivation is as follows: \\[\n\\begin{aligned}\n\\eta &= \\ln \\left(\\dfrac{\\mu}{1-\\mu}\\right) && (\\text{derived from rewriting Bernoulli distribution})\\\\\n& \\rightarrow \\exp(\\eta) = \\dfrac{\\mu}{1-\\mu} && \\text{(taking exp on both sides)}\\\\\n& \\rightarrow \\mu = \\dfrac{\\exp(\\eta)}{1+\\exp(\\eta)} && \\text{(by basic algebra)}\\\\\n& \\rightarrow \\mu = \\dfrac{1}{1+\\exp(-\\eta)} && \\text{(multiplying by $\\exp(-\\mu)$)}\n\\end{aligned}\n\\] There are many common probability distribution that is in the exponential family. The table below listed some of them.\n\n\n\n\n\n\n\n\nDistribution\nProbability Density / Mass Function\n(\\(x\\)) Values\n\n\n\n\nGaussian\n\\[ p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} \\]\n\\[ x \\in \\mathbb{R} \\]\n\n\nBernoulli\n\\[ p(x) = \\alpha^x (1 - \\alpha)^{1 - x} \\]\n\\[ x \\in \\{0, 1\\} \\]\n\n\nBinomial\n\\[ p(x) = \\binom{n}{x} \\alpha^x (1 - \\alpha)^{n - x} \\]\n\\[ x \\in \\{0, 1, 2, \\ldots, n\\} \\]\n\n\nMultinomial\n\\[ p(x) = \\frac{n!}{x_1! x_2! \\ldots x_n!} \\prod_{i=1}^{n} \\alpha_i^{x_i} \\]\n\\[ x_i \\in \\{0, 1, 2, \\ldots, n\\}, \\sum x_i = n \\]\n\n\nExponential\n\\[ p(x) = \\lambda e^{-\\lambda x} \\]\n\\[ x \\in \\mathbb{R}^+ \\]\n\n\nPoisson\n\\[ p(x) = \\frac{e^{-\\lambda} \\lambda^x}{x!} \\]\n\\[ x \\in \\{0, 1, 2, \\ldots \\} \\]\n\n\nDirichlet\n\\[ p(x) = \\frac{\\Gamma \\left( \\sum_i \\alpha_i \\right)}{\\prod_i \\Gamma(\\alpha_i)} \\prod_i x_i^{\\alpha_i - 1} \\]\n\\[ x_i \\in [0, 1], \\sum x_i = 1 \\]"
  },
  {
    "objectID": "notes/expfam/expfam.html#random-sampling",
    "href": "notes/expfam/expfam.html#random-sampling",
    "title": "The Exponential Family",
    "section": "Random sampling",
    "text": "Random sampling\nThe exponential family structure is preserved for an i.i.d. sample. If \\(\\{X_{1}, \\cdots, X_{n}\\}\\) are i.i.d. from some distribution in the exponential family \\(p(x; \\theta)\\), then the joint distribution: \\[\np(x_{1}, \\cdots, x_{n};\\theta) = \\prod_{i=1}^{n}h(x_{i})\\exp \\left[\\sum\\limits_{i=1}^{s}\\theta_{i}\\sum\\limits_{j=1}^{n}\\mathcal{T}_{i}(x_{j}) - \\eta\\mathcal{A}(\\theta)\\right]\n\\] is an exponential family with the same natural parameters but with sufficient statistics: \\[\n\\mathcal{T}_{i}(x_{1}, \\cdots, x_{n)}= \\sum\\limits_{j=1}^{n}T_i(x_{j})\n\\] d ## Log-partition generates moments\nTaking the derivative of \\(\\mathcal{A}\\) w.r.t. \\(\\theta\\), we obtain that:\\[\n\\begin{aligned}\n\\dfrac{d\\mathcal{A}}{d\\eta}\n&= \\dfrac{d}{d\\eta} \\log \\int \\exp(\\eta^{T} \\mathcal{T}(x))h(x) dx \\\\\n&= \\dfrac{\\dfrac{d}{d\\eta} \\int \\exp(\\eta^{T} \\mathcal{T}(x)h(x)dx}{\\int \\exp(\\eta^{T} \\mathcal{T}(x)h(x)dx} \\\\\n&= \\dfrac{\\int \\mathcal{T}(x) \\exp(\\eta^{T} \\mathcal{T}(x)h(x)dx}{\\exp(\\mathcal{A}(\\eta))} \\\\\n&= \\int \\mathcal{T}(x) \\exp(\\eta \\mathcal{T}(x) - \\mathcal{A}(\\eta))h(x)dx \\\\\n&= \\int \\mathcal{T}(x) p(x)dx = \\mathbb{E}[\\mathcal{T}(x)]\n\\end{aligned}\n\\]a concrete example, recall that for Bernoulli distribution, we have \\(\\mathcal{A}(\\eta) = \\log (1+e^{\\eta})\\), we can take the first-order derivative of the log-partition function and obtain the mean for Bernoulli random variables: \\[\n\\dfrac{d\\mathcal{A}}{d\\eta} = \\dfrac{d}{d\\eta} \\log (1+e^{\\eta}) = \\dfrac{e^{\\eta}}{1+e^{\\eta}} = \\dfrac{1}{1+e^{-\\eta}} = \\sigma(\\eta) = \\mu\n\\] Similarly, we can verify that higher derivatives lead to functions of higher moments as follows: \\[\n\\begin{aligned}\n\\dfrac{d^{2}\\mathcal{A}}{d\\eta} &= \\dfrac{d\\mathcal{A}}{d\\eta} \\int \\mathcal{T}(x)\\exp (\\eta^{T}\\mathcal{T}(x) - \\mathcal{A}(\\eta))h(x)dx \\\\\n&= \\int \\mathcal{T}(x) \\exp (\\eta^{T}\\mathcal{T}(x) - \\mathcal{A}(\\eta))h(x)(\\mathcal{T}(x) - \\mathcal{A}'(\\eta))dx \\\\\n&= \\int \\mathcal{T}(x)p(x)(\\mathcal{T}(x) - \\mathcal{A}'(x))dx \\\\\n&= \\int \\mathcal{T}^{2}(x)p(x)dx - \\mathcal{A}'(x)\\int \\mathcal{T}(x)p(x)dx \\\\\n&= \\mathbb{E}[\\mathcal{T}^{2}(x)] - \\mathbb{E}[\\mathcal{T}(x)]^{2} = \\text{Var}[\\mathcal{T}(x)]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "notes/expfam/expfam.html#convexity",
    "href": "notes/expfam/expfam.html#convexity",
    "title": "The Exponential Family",
    "section": "Convexity",
    "text": "Convexity\nUsing Hölder inequality together with this results, we can show that \\(\\mathcal{A}\\) is a convex function of \\(\\theta\\). In the case of the exponential family, this means that the covariance matrix (equivalent to the Hessian matrix) of the sufficient statistic \\(\\mathcal{T}_{i}\\) is positive semidefinite. Formally, we have the following theorem:\n\nThe natural parameter space \\(\\mathcal{N}\\) is a convex set and the cumulant function \\(\\mathcal{A}(\\eta)\\) is a convex function. If the family is minimal then \\(\\mathcal{A}(\\eta)\\) is strictly convex.\n\nHere, we say that an exponential family is minimal if the sufficient statistic are not redundant, i.e. there is no set of coefficients \\(\\alpha \\in \\mathbb{R}^s\\), \\(\\alpha \\# 0\\) such that: \\[\n\\sum\\limits_{i=1}^{s}\\alpha_{i}\\mathcal{T}_{i}(x) = \\text{const} \\qquad \\forall x\\in \\mathbb{R}\n\\] # Connection with Fisher information matrix\nUnder some regularity condition, the [[Fisher Information matrix]] is given by: \\[\n\\mathbf{F}(\\eta) \\triangleq \\mathbb{E}_{p(x\\vert \\eta)} [\\nabla \\log p(x \\vert \\eta) \\nabla \\log p(x \\vert \\eta)^{T}] = -\\mathbb{E}_{p(x \\vert \\eta)} [\\nabla^{2}\\log p(x\\vert \\eta)]\n\\] Recall that in the context of the exponential family, we have\nFrom the definition of the Fisher Information matrix, we can derive the following: \\[\n\\begin{aligned}\n\\mathbf{F}(\\eta) &= -\\mathbb{E}_{p(x\\vert \\eta)}[\\nabla^{2}\\log p(x\\vert \\eta)] && \\text{(by definition)}\\\\\n&= -\\mathbb{E}_{p(x \\vert \\eta)}[\\nabla^{2}_{\\eta}(\\eta^{T} \\mathcal{T}(x) - \\mathcal{A(\\eta)})] && \\text{(plug in $p(x \\vert \\eta)$)} \\\\\n&= \\nabla^{2}_{\\eta}\\mathcal{A} (\\eta) = \\text{Cov}[\\mathcal{T}(x)]\n\\end{aligned}\n\\] Intuitively, this is telling us that the Hessian of the log-partition function is the same as the Fisher Information matrix, which is the same as the covariance of the sufficient statistic."
  },
  {
    "objectID": "notes/expfam/expfam.html#footnotes",
    "href": "notes/expfam/expfam.html#footnotes",
    "title": "The Exponential Family",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhen a distribution is consistent, it means that the values are spread out in a way that shows a clear and predictable pattern. In other words, if you take multiple samples from the distribution, they should all look similar to each other and follow the same pattern or trend. This consistency makes it easier to understand and predict the behavior of the data.↩︎\nEntropy is a measure of this unpredictability or randomness. In statistics, it tells us how mixed up or uncertain the data is. High entropy means the data is very mixed and unpredictable. Low entropy means the data is more uniform and predictable.↩︎\nWe will show later that we can actually derive the probability distributions that belong to the exponential family by solving this problem but with different constraints.↩︎"
  },
  {
    "objectID": "notes/gaussian-distribution/gaussian-distribution.html",
    "href": "notes/gaussian-distribution/gaussian-distribution.html",
    "title": "Gaussian Distribution",
    "section": "",
    "text": "The Gaussian distribution, also known as the normal distribution, is the most extensively utilized probability distribution for real-valued random variables \\(y \\in \\mathbb{R}\\). In this article, we will delve into the definition of the (multivariate) Gaussian distribution and elucidate why it assumes its particular form through the principle of maximum entropy. Additionally, we will derive the normalization constant in the Gaussian probability density function (PDF)."
  },
  {
    "objectID": "notes/gaussian-distribution/gaussian-distribution.html#gaussian-distribution-derivation-from-principle-of-maximum-entropy",
    "href": "notes/gaussian-distribution/gaussian-distribution.html#gaussian-distribution-derivation-from-principle-of-maximum-entropy",
    "title": "Gaussian Distribution",
    "section": "Gaussian distribution derivation from Principle of Maximum entropy",
    "text": "Gaussian distribution derivation from Principle of Maximum entropy\n\n[!definition] For a continuous random variable \\(X\\) with a probability density function \\(p(x)\\), the entropy \\(h(X)\\) is defined as: \\[h(X) = -\\int_{-\\infty}^{\\infty} f(x) \\log f(x) \\, dx\\]\n\nMaximum entropy pdf with fixed mean \\(\\mu\\) and variance \\(\\sigma^{2}\\)\n\\[\\mathcal{L}= -\\int_{-\\infty}^{\\infty} p(x) \\log p(x)dx + \\lambda_0\\left(\\int_{-\\infty}^{\\infty} p(x)dx - 1 \\right) + \\lambda_1\\left(\\int_{-\\infty}^{\\infty}(x-\\mu)^2 p(x) dx - \\sigma^2 \\right)\\] Taking the derivative of \\(\\mathcal{L}\\) w.r.t. \\(p(x)\\), we obtain: \\[\n\\dfrac{\\partial \\mathcal{L}}{\\partial p(x)}= -(1+\\log p(x)) + \\lambda_{0}+\\lambda_{1}(x-\\mu)^{2} \\tag{4}\n\\] Setting (4) to be equal to 0, we can derive that: \\(p(x) = \\exp(\\lambda_{0}+ \\lambda(x-\\mu)^{2}-1)\\).\nWe now have to make sure that the above form of \\(p(x)\\) satisfies the initial constraints. In particular: \\[\n\\int_{-\\infty}^{\\infty} exp(\\lambda_{0}+ \\lambda(x-\\mu)^{2}-1)dx = 1 \\tag{5}\n\\] and \\[\n\\int_{-\\infty}^{\\infty}(x-\\mu)^{2}\\exp(\\lambda_{0}+ \\lambda(x-\\mu)^{2}-1)dx = \\sigma^{2} \\tag{6}\n\\] From (5) and (6), we obtain that \\(\\exp(\\lambda_{0}-1)\\sqrt{\\dfrac{-\\pi}{\\lambda_{1}}}=1\\) and \\(\\lambda_{1} = \\sqrt{\\dfrac{1}{2\\pi}}\\dfrac{1}{\\sigma}\\). Plug in everything together, we have that: \\[\n\\begin{aligned}\np(x) &= \\exp(\\lambda_{0}+ \\lambda(x-\\mu)^{2}-1) \\\\\n&= \\exp(\\lambda_{0}-1) + \\exp(\\lambda_{1}(x-\\mu)^{2})\\\\\n&= \\dfrac{1}{\\sqrt{2\\pi \\sigma^{2}}}\\exp\\left(-\\dfrac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right)\n\\end{aligned}\n\\] which is exactly the form of the PDF of the Gaussian distribution."
  },
  {
    "objectID": "misc.html",
    "href": "misc.html",
    "title": "Misc",
    "section": "",
    "text": "https://leimao.github.io/blog/\nhttps://francisbach.com/\nhttps://davidstutz.de/category/blog/"
  },
  {
    "objectID": "misc.html#some-activities-i-participated-in.",
    "href": "misc.html#some-activities-i-participated-in.",
    "title": "Misc",
    "section": "",
    "text": "Me and Prof. Chris Manning at AI Day 2023 organized by VinAI."
  },
  {
    "objectID": "misc.html#good-blogs",
    "href": "misc.html#good-blogs",
    "title": "Misc",
    "section": "",
    "text": "https://leimao.github.io/blog/\nhttps://francisbach.com/\nhttps://davidstutz.de/category/blog/"
  },
  {
    "objectID": "draft/sm/sm.html",
    "href": "draft/sm/sm.html",
    "title": "Generative Score Models",
    "section": "",
    "text": "Denoising Score Matching (DSM) is a variant of score matching that does not require the Hessian computation. Consider a noise distribution \\(q_{\\sigma}(\\mathbf{\\tilde{x}} \\vert \\mathbf{x})\\), and let \\(q_{\\sigma}(\\mathbf{x}) = \\int q_{\\sigma}(\\mathbf{\\tilde{x}} \\vert \\mathbf{x}) p_{d}(\\mathbf{x})d\\mathbf{x}\\). DSM applies the original score matching to the noise-corrupted data distribution \\(q_{\\sigma}(\\tilde{\\mathbf{x}})\\) and the objective can be proven to be equivalent up to a constant.\nWhile DSM is much faster than score matching, it does have several drawbacks, including (1) it can only recover the noise corrupted data distribution; (2) it is hard to choose the parameters of the noise distribution\n\n\n\nThe main intuition behind Sliced score matching (Song et al. 2019) is that working with low-dimensional data is easier than high-dimensional data. Therefore we can project the high-dimensional data into a lower dimension space according to some random direction \\(\\mathbf{v}\\).\nProjecting \\(s_d(\\mathbf{x})\\) and \\(s_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\) onto some random direction \\(\\mathbf{v}\\) and propose to compare their average difference along that random direction. Consider the following objective as an alternative to the Fisher Divergence: \\[\nL(\\boldsymbol{\\theta};p_{\\mathbf{v}}) := \\dfrac{1}{2} \\mathbb{E}_{p_{\\mathbf{v}}} \\mathbb{E}_{p_{\\mathbf{d}}} [(\\mathbf{v}^{T}s_{m}(\\mathbf{x};\\boldsymbol{\\theta}) -\\mathbf{v}^{T}s_{d}(\\mathbf{x}))^{2}]  \n\\] where \\(\\mathbf{v} \\sim p_\\mathbf{v}\\) and \\(\\mathbf{x} \\sim p_{d}\\) are independent, and we require\nFor instance \\(p_\\mathbf{v}\\) can be a multivariate standard normal \\(\\mathcal{N}(0,I_{D})\\), a multivariate Rademacher distribution (the uniform distribution over \\(\\{+1\\}^{D}\\)), or a uniform distribution over a hypersphere \\(\\mathbb{S}^{D-1}\\). \\[J(\\boldsymbol{\\theta};p_{\\mathbf{v}}):=\\mathbb{E}_{{p_{\\mathbf{v}}}}\\mathbb{E}_{{p_{d}}}{\\left[\\mathbf{v}^{\\mathsf{T}}\\nabla_{\\mathbf{x}}\\boldsymbol{s}_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\mathbf{v}+\\frac{1}{2}\\left(\\mathbf{v}^{\\mathsf{T}}\\boldsymbol{s}_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\right)^{2}\\right]}\\]"
  },
  {
    "objectID": "draft/sm/sm.html#denoising-score-matching",
    "href": "draft/sm/sm.html#denoising-score-matching",
    "title": "Generative Score Models",
    "section": "",
    "text": "Denoising Score Matching (DSM) is a variant of score matching that does not require the Hessian computation. Consider a noise distribution \\(q_{\\sigma}(\\mathbf{\\tilde{x}} \\vert \\mathbf{x})\\), and let \\(q_{\\sigma}(\\mathbf{x}) = \\int q_{\\sigma}(\\mathbf{\\tilde{x}} \\vert \\mathbf{x}) p_{d}(\\mathbf{x})d\\mathbf{x}\\). DSM applies the original score matching to the noise-corrupted data distribution \\(q_{\\sigma}(\\tilde{\\mathbf{x}})\\) and the objective can be proven to be equivalent up to a constant.\nWhile DSM is much faster than score matching, it does have several drawbacks, including (1) it can only recover the noise corrupted data distribution; (2) it is hard to choose the parameters of the noise distribution"
  },
  {
    "objectID": "draft/sm/sm.html#sliced-score-matching",
    "href": "draft/sm/sm.html#sliced-score-matching",
    "title": "Generative Score Models",
    "section": "",
    "text": "The main intuition behind Sliced score matching (Song et al. 2019) is that working with low-dimensional data is easier than high-dimensional data. Therefore we can project the high-dimensional data into a lower dimension space according to some random direction \\(\\mathbf{v}\\).\nProjecting \\(s_d(\\mathbf{x})\\) and \\(s_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\) onto some random direction \\(\\mathbf{v}\\) and propose to compare their average difference along that random direction. Consider the following objective as an alternative to the Fisher Divergence: \\[\nL(\\boldsymbol{\\theta};p_{\\mathbf{v}}) := \\dfrac{1}{2} \\mathbb{E}_{p_{\\mathbf{v}}} \\mathbb{E}_{p_{\\mathbf{d}}} [(\\mathbf{v}^{T}s_{m}(\\mathbf{x};\\boldsymbol{\\theta}) -\\mathbf{v}^{T}s_{d}(\\mathbf{x}))^{2}]  \n\\] where \\(\\mathbf{v} \\sim p_\\mathbf{v}\\) and \\(\\mathbf{x} \\sim p_{d}\\) are independent, and we require\nFor instance \\(p_\\mathbf{v}\\) can be a multivariate standard normal \\(\\mathcal{N}(0,I_{D})\\), a multivariate Rademacher distribution (the uniform distribution over \\(\\{+1\\}^{D}\\)), or a uniform distribution over a hypersphere \\(\\mathbb{S}^{D-1}\\). \\[J(\\boldsymbol{\\theta};p_{\\mathbf{v}}):=\\mathbb{E}_{{p_{\\mathbf{v}}}}\\mathbb{E}_{{p_{d}}}{\\left[\\mathbf{v}^{\\mathsf{T}}\\nabla_{\\mathbf{x}}\\boldsymbol{s}_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\mathbf{v}+\\frac{1}{2}\\left(\\mathbf{v}^{\\mathsf{T}}\\boldsymbol{s}_{m}(\\mathbf{x};\\boldsymbol{\\theta})\\right)^{2}\\right]}\\]"
  },
  {
    "objectID": "notes/expfam/expfam.html#log-partition-generates-moments",
    "href": "notes/expfam/expfam.html#log-partition-generates-moments",
    "title": "The Exponential Family",
    "section": "Log-partition generates moments",
    "text": "Log-partition generates moments\nTaking the derivative of \\(\\mathcal{A}\\) w.r.t. \\(\\theta\\), we obtain that:\\[\n\\begin{aligned}\n\\dfrac{d\\mathcal{A}}{d\\eta}\n&= \\dfrac{d}{d\\eta} \\log \\int \\exp(\\eta^{T} \\mathcal{T}(x))h(x) dx \\\\\n&= \\dfrac{\\dfrac{d}{d\\eta} \\int \\exp(\\eta^{T} \\mathcal{T}(x)h(x)dx}{\\int \\exp(\\eta^{T} \\mathcal{T}(x)h(x)dx} \\\\\n&= \\dfrac{\\int \\mathcal{T}(x) \\exp(\\eta^{T} \\mathcal{T}(x)h(x)dx}{\\exp(\\mathcal{A}(\\eta))} \\\\\n&= \\int \\mathcal{T}(x) \\exp(\\eta \\mathcal{T}(x) - \\mathcal{A}(\\eta))h(x)dx \\\\\n&= \\int \\mathcal{T}(x) p(x)dx = \\mathbb{E}[\\mathcal{T}(x)]\n\\end{aligned}\n\\]a concrete example, recall that for Bernoulli distribution, we have \\(\\mathcal{A}(\\eta) = \\log (1+e^{\\eta})\\), we can take the first-order derivative of the log-partition function and obtain the mean for Bernoulli random variables: \\[\n\\dfrac{d\\mathcal{A}}{d\\eta} = \\dfrac{d}{d\\eta} \\log (1+e^{\\eta}) = \\dfrac{e^{\\eta}}{1+e^{\\eta}} = \\dfrac{1}{1+e^{-\\eta}} = \\sigma(\\eta) = \\mu\n\\] Similarly, we can verify that higher derivatives lead to functions of higher moments as follows: \\[\n\\begin{aligned}\n\\dfrac{d^{2}\\mathcal{A}}{d\\eta} &= \\dfrac{d\\mathcal{A}}{d\\eta} \\int \\mathcal{T}(x)\\exp (\\eta^{T}\\mathcal{T}(x) - \\mathcal{A}(\\eta))h(x)dx \\\\\n&= \\int \\mathcal{T}(x) \\exp (\\eta^{T}\\mathcal{T}(x) - \\mathcal{A}(\\eta))h(x)(\\mathcal{T}(x) - \\mathcal{A}'(\\eta))dx \\\\\n&= \\int \\mathcal{T}(x)p(x)(\\mathcal{T}(x) - \\mathcal{A}'(x))dx \\\\\n&= \\int \\mathcal{T}^{2}(x)p(x)dx - \\mathcal{A}'(x)\\int \\mathcal{T}(x)p(x)dx \\\\\n&= \\mathbb{E}[\\mathcal{T}^{2}(x)] - \\mathbb{E}[\\mathcal{T}(x)]^{2} = \\text{Var}[\\mathcal{T}(x)]\n\\end{aligned}\n\\]"
  }
]